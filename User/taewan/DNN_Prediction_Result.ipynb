{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################Import Modules#######################\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(777) \n",
    "\n",
    "\n",
    "##################Define Functions#####################\n",
    "def five_fold_name(data,i):\n",
    "    test_names = data[data['index']==i+1]\n",
    "    \n",
    "    \n",
    "def five_fold(data, i):\n",
    "    test_data = data[data['index']==i+1]\n",
    "    train_data = data[(data['index']<i+1) | (data['index']>i+1)]\n",
    "    print(len(test_data), len(train_data))\n",
    "    \n",
    "    return train_data , test_data\n",
    "\n",
    "def set_train_three_layer(repeat, nodes, learning_rate):\n",
    "    batch_size = 1000\n",
    "    tf.reset_default_graph()\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, [None, cnt_train])\n",
    "    Y = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "    W1 = tf.get_variable( shape= [cnt_train, nodes[0]], name='weight1' , initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.Variable(tf.random_normal([nodes[0]]), name='bias1')\n",
    "    layer1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "    layer1 = tf.nn.dropout(layer1, keep_prob=keep_prob)\n",
    "\n",
    "    W2 = tf.get_variable(shape =[nodes[0], nodes[1]], name='weight2', initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.Variable(tf.random_normal([nodes[1]]), name='bias2')\n",
    "    layer2 = tf.nn.relu(tf.matmul(layer1, W2) + b2)\n",
    "    layer2 = tf.nn.dropout(layer2 , keep_prob=keep_prob)\n",
    "\n",
    "    W3 = tf.get_variable(shape= [nodes[1], nodes[2]], name='weight3',initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.Variable(tf.random_normal([nodes[2]]), name='bias3')\n",
    "    layer3 = tf.nn.relu(tf.matmul(layer2, W3) + b3)\n",
    "    layer3 = tf.nn.dropout(layer3, keep_prob=keep_prob)\n",
    "\n",
    "    W4 = tf.get_variable(shape=[nodes[2], 2], name='weight4',initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b4 = tf.Variable(tf.random_normal([2]), name='bias4')\n",
    "    hypothesis = tf.matmul(layer3, W4) + b4\n",
    "\n",
    "\n",
    "\n",
    "    # cost/loss function\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "\n",
    "    # Accuracy computation\n",
    "    # True if hypothesis>0.5 else False\n",
    "\n",
    "    predicted = tf.argmax(hypothesis,1)\n",
    "    correct_prediction = tf.equal(predicted,tf.argmax(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float32))\n",
    "    with tf.Session() as sess:\n",
    "        # Initialize TensorFlow variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for step in range(repeat):\n",
    "            avg_cost = 0\n",
    "            total_num = int(len(train_x)/batch_size)\n",
    "\n",
    "            for i in range(total_num):\n",
    "                batch_x = train_x[i*batch_size:(i+1)*batch_size]\n",
    "                batch_y = train_y[i*batch_size:(i+1)*batch_size]\n",
    "                sess.run( train , feed_dict={X: batch_x, Y: batch_y , keep_prob : 0.7})\n",
    "\n",
    "            if step == repeat-1:\n",
    "                ####Train Accuracy report####\n",
    "                train_h, train_p, train_a = sess.run([hypothesis, predicted, accuracy],feed_dict={X: train_x, Y: train_y, keep_prob :0.7})\n",
    "                print(\"\\nTrain Accuracy: \", train_a)\n",
    "            if step % 20 == 0 :\n",
    "                train_h,c, train_p,train_a = sess.run([hypothesis, cost ,predicted, accuracy],feed_dict={X: train_x, Y: train_y, keep_prob :0.7})\n",
    "                print(\"\\nCurrent Accuracy : \", train_a , \"cost : \", c , \"Current Step : \", step)\n",
    "                if train_a > 0.97 :\n",
    "                    break\n",
    "        test_h, test_p, test_a = sess.run([hypothesis, predicted, accuracy],feed_dict={X: test_x, Y: test_y, keep_prob :1.0})\n",
    "        print(\"\\nTest Accuracy: \", test_a)\n",
    "\n",
    "    return train_p ,train_h, test_p,test_h \n",
    "\n",
    "##################READ DATA############################\n",
    "datafilename = \"/Users/taewan/Desktop/Ahn/FinalData_GSM_gene_index_result.csv\"\n",
    "data = pd.read_csv(datafilename)\n",
    "repeat, layer, node , learning_rate, gene = 100, 3,'1500 1500 1500' ,0.01 , 60\n",
    "output_directory = '/Users/taewan/Desktop/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0   XIST  HLA-DRB4 /// LOC100509582  CMPK2   MMP1  RPS4Y1  \\\n",
      "0      GSM253210  3.371                     -0.149 -0.871 -1.346  -0.195   \n",
      "1      GSM253216  2.780                     -0.126 -1.122 -1.338  -0.037   \n",
      "2      GSM256745 -0.981                      0.330  2.377 -0.758   3.468   \n",
      "3      GSM256746 -0.977                      0.112  2.714 -0.796   3.385   \n",
      "4      GSM256747 -0.993                      0.295  3.745 -0.620   3.251   \n",
      "5      GSM256748 -1.040                      3.567  1.650  0.179   3.515   \n",
      "6      GSM256749 -0.973                      3.489  1.610  0.753   3.379   \n",
      "7      GSM256750 -0.957                      3.228  3.825 -0.047   3.257   \n",
      "8      GSM257187  1.870                      0.321  0.934 -1.383   1.900   \n",
      "9      GSM257190  1.410                      0.437  1.166 -1.374   2.342   \n",
      "10     GSM257248 -1.137                     -0.603  0.917  3.185   2.829   \n",
      "11     GSM257249 -1.157                     -0.703  0.970  3.185   2.819   \n",
      "12     GSM257525  0.780                     -1.358 -0.036 -1.832   0.084   \n",
      "13     GSM257526  0.776                     -1.544 -0.145 -1.544  -0.679   \n",
      "14     GSM257527  0.982                     -1.300 -0.125 -2.060  -0.274   \n",
      "15     GSM257528  1.019                     -1.338  0.232 -1.700  -0.151   \n",
      "16     GSM257660 -1.100                     -1.169  1.216 -1.402   2.231   \n",
      "17     GSM257661 -0.461                     -1.328  1.133 -2.064   2.143   \n",
      "18     GSM257471 -0.588                     -1.514  1.063 -1.524   2.359   \n",
      "19     GSM257472 -2.054                     -1.217  1.125 -1.545   2.285   \n",
      "20     GSM259831 -0.496                     -1.510 -1.115 -2.138  -0.760   \n",
      "21     GSM259832 -0.727                     -1.469 -0.598 -0.222  -0.095   \n",
      "22     GSM259833 -0.474                     -1.114 -0.523 -1.568  -1.430   \n",
      "23     GSM259834 -0.972                     -1.271  0.107 -0.693  -1.227   \n",
      "24     GSM259835 -1.441                     -1.718 -0.191 -1.427  -1.321   \n",
      "25     GSM259836 -0.298                     -1.449  0.082 -2.178  -0.691   \n",
      "26     GSM260250 -0.800                     -0.800  0.088  1.983  -0.800   \n",
      "27     GSM260251 -0.799                     -0.799  0.172  2.054  -0.799   \n",
      "28     GSM260252 -0.798                     -0.799  0.105  1.834  -0.796   \n",
      "29     GSM260253 -0.798                     -0.798  0.093  1.881  -0.798   \n",
      "...          ...    ...                        ...    ...    ...     ...   \n",
      "11883  GSM251103 -0.399                     -1.645  0.196 -0.389  -0.105   \n",
      "11884  GSM251108 -0.481                     -1.640  0.722 -0.838   0.109   \n",
      "11885  GSM251101 -0.345                      0.807  0.813 -1.997   2.463   \n",
      "11886  GSM251105  1.983                     -1.338  0.801 -1.595  -0.605   \n",
      "11887  GSM251110  2.083                      1.179  0.750 -1.959  -0.042   \n",
      "11888  GSM251111  0.027                      0.605  0.646 -0.886   2.585   \n",
      "11889  GSM251114  1.900                      0.837  0.931 -1.765   0.564   \n",
      "11890  GSM251126  2.090                     -1.377  0.897 -1.620   0.104   \n",
      "11891  GSM251129  0.197                      0.817  1.022 -1.073   2.455   \n",
      "11892  GSM251192 -0.326                     -1.068  0.790 -1.156   2.469   \n",
      "11893  GSM251194  1.905                     -1.040  0.957 -1.849   0.254   \n",
      "11894  GSM251195  1.829                     -1.025  1.468 -1.974   0.319   \n",
      "11895  GSM251196  1.835                     -0.932  1.841 -1.764   0.377   \n",
      "11896  GSM251197 -0.305                     -1.029  1.873 -1.226   2.433   \n",
      "11897  GSM251198 -0.219                     -0.893  1.510 -1.647   2.472   \n",
      "11898  GSM251199 -0.613                     -0.925  1.599 -1.462   2.387   \n",
      "11899  GSM251200 -0.422                     -1.507  1.321 -1.700   2.429   \n",
      "11900  GSM251207 -0.527                      1.210  1.811 -1.504   2.481   \n",
      "11901  GSM251208  1.711                      1.209  1.991 -0.718   0.660   \n",
      "11902  GSM251209  1.657                     -1.121  1.609 -1.457   0.395   \n",
      "11903  GSM251210  0.150                     -1.023  1.067 -1.747   2.396   \n",
      "11904  GSM251211  1.730                     -1.497  1.762 -1.229   0.676   \n",
      "11905  GSM251212  0.870                     -1.056 -0.750 -0.565  -0.433   \n",
      "11906  GSM251582  0.972                     -1.030 -0.525 -0.731  -0.141   \n",
      "11907  GSM251583  0.980                     -1.042 -0.485 -0.659  -0.433   \n",
      "11908  GSM251584 -0.337                     -1.237  0.070 -0.626   2.623   \n",
      "11909  GSM251585 -0.340                     -1.213 -0.194 -0.839   2.605   \n",
      "11910  GSM251587 -1.022                     -1.058 -0.671 -0.542   2.762   \n",
      "11911  GSM251589 -0.787                     -1.048 -0.578 -0.765   2.761   \n",
      "11912  GSM251590 -0.989                     -1.040 -0.291 -0.484   2.779   \n",
      "\n",
      "       IGHA1 /// IGHA2 /// LOC100126583    IL8   EGFR  CHI3L1   ...     EREG  \\\n",
      "0                                -0.548 -0.649  0.967  -1.239   ...   -0.713   \n",
      "1                                -0.480 -0.656  1.234  -1.161   ...   -0.813   \n",
      "2                                 1.566  4.167  2.747  -0.048   ...    1.237   \n",
      "3                                 1.768  4.286  2.849  -0.246   ...    0.920   \n",
      "4                                 0.747  4.132  2.908  -0.574   ...    0.535   \n",
      "5                                 2.049  4.449  3.140  -0.050   ...    0.913   \n",
      "6                                 2.076  4.353  2.827   0.207   ...    0.697   \n",
      "7                                 1.678  4.070  2.693  -0.084   ...    0.415   \n",
      "8                                -1.420 -0.366  0.708  -1.420   ...    0.450   \n",
      "9                                -1.396 -0.412 -0.597  -1.535   ...    0.640   \n",
      "10                               -0.526  3.506  0.671  -0.786   ...   -0.241   \n",
      "11                               -0.694  3.480  0.234  -0.910   ...   -0.354   \n",
      "12                               -1.737  0.686 -0.063  -0.575   ...   -0.530   \n",
      "13                               -1.544  0.418  0.051  -1.679   ...   -1.167   \n",
      "14                               -1.590  0.407 -0.698  -1.700   ...   -0.873   \n",
      "15                               -1.723  0.030  0.063  -1.504   ...   -0.720   \n",
      "16                               -1.571  0.202 -0.274  -1.451   ...   -0.861   \n",
      "17                               -1.516  1.007 -0.227  -1.594   ...   -1.068   \n",
      "18                               -1.128 -1.413 -0.869  -1.104   ...   -0.664   \n",
      "19                               -1.167 -0.276 -1.422  -1.482   ...   -1.339   \n",
      "20                               -1.463  0.863 -1.481  -1.500   ...    0.484   \n",
      "21                               -1.585  0.739 -1.270  -1.131   ...    0.594   \n",
      "22                               -1.650  0.772 -0.928  -1.378   ...    0.520   \n",
      "23                               -1.354  1.926 -0.496  -0.505   ...    0.723   \n",
      "24                               -1.528  1.984 -0.585  -0.214   ...    0.775   \n",
      "25                               -1.670  2.003 -0.106  -0.872   ...    0.813   \n",
      "26                               -0.781  1.779  0.452  -0.800   ...   -0.801   \n",
      "27                               -0.778  1.785  0.496  -0.798   ...   -0.792   \n",
      "28                               -0.780  1.830  0.619  -0.798   ...   -0.799   \n",
      "29                               -0.779  1.836  0.776  -0.797   ...   -0.799   \n",
      "...                                 ...    ...    ...     ...   ...      ...   \n",
      "11883                            -1.548 -0.946 -0.192  -1.381   ...   -0.345   \n",
      "11884                            -1.841 -0.456 -0.723  -2.093   ...   -0.201   \n",
      "11885                            -1.822  0.027  1.056  -1.860   ...   -0.561   \n",
      "11886                            -1.595 -0.253  1.009  -1.293   ...    0.113   \n",
      "11887                            -1.602 -0.245  0.943  -1.553   ...   -0.184   \n",
      "11888                            -1.728  0.210  1.226  -1.541   ...   -0.124   \n",
      "11889                            -1.441  0.073  0.852  -1.856   ...   -0.720   \n",
      "11890                            -1.495  0.145  0.765  -1.080   ...    0.076   \n",
      "11891                            -1.242  0.032  0.851  -1.920   ...   -0.357   \n",
      "11892                            -1.782 -0.039  1.217  -0.557   ...   -0.133   \n",
      "11893                            -1.616 -0.101  0.865  -0.849   ...   -0.161   \n",
      "11894                            -1.545  0.087  1.146  -1.765   ...   -0.571   \n",
      "11895                            -1.938  0.322  0.979  -1.511   ...   -0.071   \n",
      "11896                            -0.275  0.011  1.195  -1.304   ...   -1.054   \n",
      "11897                            -1.153  0.013  1.235  -1.917   ...   -0.481   \n",
      "11898                             1.236 -0.125  0.659  -1.620   ...   -0.688   \n",
      "11899                             0.599 -0.008  0.881  -1.302   ...   -0.611   \n",
      "11900                            -1.601 -0.009  1.124  -1.601   ...   -1.033   \n",
      "11901                            -1.473  0.124  0.657  -1.892   ...   -0.518   \n",
      "11902                            -0.380 -0.027  1.188  -1.919   ...   -0.322   \n",
      "11903                             0.163 -0.372  0.662  -1.364   ...   -0.416   \n",
      "11904                            -1.714 -0.169  0.946  -1.543   ...   -1.064   \n",
      "11905                            -1.056 -0.613 -0.444   1.616   ...   -1.056   \n",
      "11906                            -1.030  0.254 -0.776   2.172   ...   -0.694   \n",
      "11907                            -1.042  0.028 -0.217   2.207   ...   -0.656   \n",
      "11908                            -1.237 -0.040  0.225   1.284   ...   -0.312   \n",
      "11909                            -1.213  0.128 -0.634   1.369   ...   -0.151   \n",
      "11910                            -1.058 -0.407  0.182   1.848   ...   -1.058   \n",
      "11911                            -1.048 -0.108 -0.145   1.855   ...   -1.048   \n",
      "11912                            -1.040 -0.303 -1.040   1.906   ...   -1.040   \n",
      "\n",
      "       CAPZA2  KLHL8  SNAI3  LOC283587  LOC727916  LOC100128439  RPAP3  index  \\\n",
      "0      -1.278 -0.033 -1.147     -1.414     -1.276        -1.006  0.405      2   \n",
      "1      -1.396 -0.086 -1.140     -1.323     -1.291        -1.151 -0.051      2   \n",
      "2      -1.014 -1.058 -0.649     -1.094     -0.998        -0.260 -0.592      3   \n",
      "3      -0.986 -1.009 -0.670     -0.910     -0.946        -0.060 -0.626      2   \n",
      "4      -1.034 -1.127 -0.659     -0.988     -0.996        -0.340 -0.585      1   \n",
      "5      -1.012 -1.078 -0.686     -1.053     -1.065        -0.326 -0.702      5   \n",
      "6      -1.029 -1.066 -0.668     -0.925     -1.023        -0.185 -0.547      1   \n",
      "7      -1.010 -0.853 -0.672     -0.969     -0.988        -0.414 -0.665      5   \n",
      "8       0.062  0.117 -0.840     -1.233     -1.312         0.160 -0.096      5   \n",
      "9       0.283  0.315 -0.968     -0.926     -0.064         0.070  0.085      3   \n",
      "10     -1.141 -1.161 -0.875     -1.042     -0.499        -1.083 -0.616      4   \n",
      "11     -1.193 -1.094 -0.978     -1.071     -0.396        -1.014 -0.552      5   \n",
      "12     -1.370 -0.737 -0.292     -1.656     -0.403        -0.644  0.501      1   \n",
      "13     -1.734 -0.600 -1.217     -1.794     -1.376        -1.706  0.470      5   \n",
      "14     -2.244 -0.560 -0.301     -2.144     -0.489        -1.471  0.322      5   \n",
      "15     -1.247 -0.964 -1.022     -0.483     -0.661        -2.096  0.310      3   \n",
      "16     -0.584 -0.733 -0.241     -1.830     -1.210        -0.620  0.969      5   \n",
      "17     -0.650 -0.583 -0.218     -0.610     -0.532        -0.802  0.917      3   \n",
      "18     -1.651 -0.915 -0.369     -1.804     -1.561        -0.737  1.121      5   \n",
      "19     -1.286 -0.393 -1.217     -1.630     -0.955        -1.322  1.116      2   \n",
      "20     -2.222 -0.481 -0.119     -1.645      0.123        -0.160  0.660      2   \n",
      "21     -0.573 -0.602 -0.262     -2.192     -0.275        -0.760  0.643      2   \n",
      "22     -0.440 -0.654 -0.344     -1.347     -0.001        -0.524  0.681      1   \n",
      "23     -0.465 -0.173 -0.382     -1.963      0.145        -0.519  0.726      1   \n",
      "24     -0.904 -0.383 -1.105     -1.574      0.054        -0.225  0.534      3   \n",
      "25     -1.356 -1.125 -0.434     -1.466      0.253        -0.633  0.839      2   \n",
      "26     -0.775 -0.780 -0.801     -0.800      0.640        -0.800  0.925      2   \n",
      "27     -0.797 -0.779 -0.800     -0.799      0.539        -0.798  0.928      2   \n",
      "28     -0.797 -0.779 -0.799     -0.798      0.353        -0.798  0.882      3   \n",
      "29     -0.785 -0.741 -0.799     -0.797      0.454        -0.798  0.885      2   \n",
      "...       ...    ...    ...        ...        ...           ...    ...    ...   \n",
      "11883  -0.480 -0.540 -1.601     -0.833     -0.540        -1.302 -0.517      5   \n",
      "11884  -0.273 -0.037 -2.082     -1.023     -0.540        -0.600 -0.626      3   \n",
      "11885  -0.809 -0.577  0.732     -1.947     -0.440        -1.947 -0.519      4   \n",
      "11886  -0.672 -0.392  0.788     -1.950     -0.664        -1.777 -0.605      5   \n",
      "11887  -0.733 -0.396  0.625     -1.019     -0.571        -1.717 -0.611      5   \n",
      "11888  -1.120 -0.748  0.686     -1.218     -0.567        -1.541 -0.507      3   \n",
      "11889  -0.917 -0.266  0.382     -1.592     -0.730        -1.856 -0.208      4   \n",
      "11890  -0.763  0.008  0.473     -0.894     -1.240        -1.593 -0.373      2   \n",
      "11891  -1.134 -0.279  0.485     -1.920     -0.716        -1.827 -0.104      4   \n",
      "11892  -0.961 -0.547  0.461     -1.324     -0.503        -1.873 -0.602      1   \n",
      "11893  -0.928 -0.584  0.714     -0.557     -0.697        -1.849 -0.355      3   \n",
      "11894  -0.803 -0.504  0.668     -1.974     -0.986        -1.671 -0.613      3   \n",
      "11895  -0.737 -0.107  0.613     -0.873     -0.608        -1.980 -0.351      5   \n",
      "11896  -0.659 -0.696  0.618     -0.989     -0.628        -1.979 -0.400      4   \n",
      "11897  -1.917 -0.361  0.664     -1.060     -1.060        -1.917 -0.411      3   \n",
      "11898  -1.853 -0.485  0.590     -1.853     -1.276        -1.590 -0.415      4   \n",
      "11899  -0.976 -0.251  0.482     -0.849     -1.157        -1.813 -0.403      1   \n",
      "11900  -1.163 -0.903  0.761     -1.927     -0.783        -1.927 -0.427      5   \n",
      "11901  -0.898 -0.333  0.608     -0.990     -0.743        -1.519 -0.345      1   \n",
      "11902  -0.998 -0.384  0.730     -0.887     -0.642        -1.638 -0.458      3   \n",
      "11903  -1.015 -0.445  0.584     -0.670     -0.499        -1.917 -0.705      1   \n",
      "11904  -0.847 -0.600  0.673     -1.192     -1.299        -1.871 -0.383      2   \n",
      "11905  -1.056 -0.800 -0.613     -1.056     -0.247        -0.729  0.487      4   \n",
      "11906  -1.030 -0.828 -0.763     -1.030     -0.185        -0.610  0.355      5   \n",
      "11907  -1.042 -1.042 -1.042     -1.042     -0.111        -0.619  0.445      2   \n",
      "11908  -0.869 -1.237 -0.375     -1.237     -0.557        -0.822  0.331      5   \n",
      "11909  -1.213 -0.689 -0.655     -1.213     -0.035        -1.213  0.311      3   \n",
      "11910  -1.058 -1.025 -1.007     -1.058     -0.087        -0.888  0.260      4   \n",
      "11911  -1.048 -0.862 -1.048     -1.048      0.019        -0.998  0.108      5   \n",
      "11912  -1.040 -0.678 -0.633     -1.040     -0.015        -1.040  0.140      5   \n",
      "\n",
      "       result  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "5           0  \n",
      "6           0  \n",
      "7           0  \n",
      "8           0  \n",
      "9           0  \n",
      "10          1  \n",
      "11          1  \n",
      "12          0  \n",
      "13          0  \n",
      "14          0  \n",
      "15          0  \n",
      "16          0  \n",
      "17          0  \n",
      "18          1  \n",
      "19          1  \n",
      "20          1  \n",
      "21          1  \n",
      "22          1  \n",
      "23          1  \n",
      "24          1  \n",
      "25          1  \n",
      "26          1  \n",
      "27          1  \n",
      "28          1  \n",
      "29          1  \n",
      "...       ...  \n",
      "11883       0  \n",
      "11884       0  \n",
      "11885       0  \n",
      "11886       0  \n",
      "11887       0  \n",
      "11888       0  \n",
      "11889       0  \n",
      "11890       0  \n",
      "11891       0  \n",
      "11892       0  \n",
      "11893       0  \n",
      "11894       0  \n",
      "11895       0  \n",
      "11896       0  \n",
      "11897       0  \n",
      "11898       0  \n",
      "11899       0  \n",
      "11900       0  \n",
      "11901       0  \n",
      "11902       0  \n",
      "11903       0  \n",
      "11904       0  \n",
      "11905       0  \n",
      "11906       0  \n",
      "11907       0  \n",
      "11908       0  \n",
      "11909       0  \n",
      "11910       0  \n",
      "11911       0  \n",
      "11912       0  \n",
      "\n",
      "[11913 rows x 6003 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2432 9481\n",
      "      0  1\n",
      "0     1  0\n",
      "1     1  0\n",
      "2     1  0\n",
      "3     1  0\n",
      "4     1  0\n",
      "5     1  0\n",
      "6     1  0\n",
      "7     1  0\n",
      "8     0  1\n",
      "9     0  1\n",
      "10    1  0\n",
      "11    1  0\n",
      "12    1  0\n",
      "13    1  0\n",
      "14    1  0\n",
      "15    0  1\n",
      "16    0  1\n",
      "17    0  1\n",
      "18    0  1\n",
      "19    0  1\n",
      "20    0  1\n",
      "21    0  1\n",
      "22    0  1\n",
      "23    0  1\n",
      "24    0  1\n",
      "25    0  1\n",
      "26    0  1\n",
      "27    0  1\n",
      "28    0  1\n",
      "29    0  1\n",
      "...  .. ..\n",
      "9451  1  0\n",
      "9452  1  0\n",
      "9453  1  0\n",
      "9454  1  0\n",
      "9455  1  0\n",
      "9456  1  0\n",
      "9457  1  0\n",
      "9458  1  0\n",
      "9459  1  0\n",
      "9460  1  0\n",
      "9461  1  0\n",
      "9462  1  0\n",
      "9463  1  0\n",
      "9464  1  0\n",
      "9465  1  0\n",
      "9466  1  0\n",
      "9467  1  0\n",
      "9468  1  0\n",
      "9469  1  0\n",
      "9470  1  0\n",
      "9471  1  0\n",
      "9472  1  0\n",
      "9473  1  0\n",
      "9474  1  0\n",
      "9475  1  0\n",
      "9476  1  0\n",
      "9477  1  0\n",
      "9478  1  0\n",
      "9479  1  0\n",
      "9480  1  0\n",
      "\n",
      "[9481 rows x 2 columns]\n",
      "\n",
      "Current Accuracy :  0.518405 cost :  2.9212 Current Step :  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f16baa5eb5fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcnt_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtrain_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_h\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_p\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtest_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mset_train_three_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_GSM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_p\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_h\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-c9641e1f3de1>\u001b[0m in \u001b[0;36mset_train_three_layer\u001b[0;34m(repeat, nodes, learning_rate)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/taewan/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/taewan/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/taewan/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/taewan/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/taewan/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "for j in range(5):\n",
    "    nodes = list(map(int , node.split(\" \")))\n",
    "    #####Five fold#####\n",
    "    train_data, test_data = five_fold(data, j)\n",
    "    train_GSM = train_data.iloc[:,0]\n",
    "    test_GSM = test_data.iloc[:,0]\n",
    "    #####Train Data Set#####\n",
    "    train_x = train_data.iloc[:,1:-2]\n",
    "    train_x = train_x.as_matrix()\n",
    "    train_y = train_data.iloc[:,-1].as_matrix()\n",
    "    train_y = train_y.flatten()\n",
    "    train_y = pd.get_dummies(train_y)\n",
    "\n",
    "    #####Test Data Set#####\n",
    "    test_x = test_data.iloc[:,1:-2]\n",
    "    test_x = test_x.as_matrix()\n",
    "    test_y = test_data.iloc[:,-1].as_matrix()\n",
    "    test_y = test_y.flatten()\n",
    "    test_y = pd.get_dummies(test_y)\n",
    "    print(train_y)\n",
    "    \n",
    "    cnt_train = len(train_x[1, :])\n",
    "    train_p, train_h , test_p ,test_h = (set_train_three_layer(repeat, nodes, learning_rate))\n",
    "    train_result = pd.concat([train_GSM, train_p], axis=1)\n",
    "    train_result = pd.concat([train_result, train_h], axis =1 )\n",
    "    test_result = pd.concat([test_GSM, test_p], axis=1)\n",
    "    test_result = pd.concat([test_result, test_h], axis=1)\n",
    "    \n",
    "    result_train_filename = \"result_file_train\" + str(j) +\".csv\"\n",
    "    train_result.to_csv(output_directory+result_train_filename , sep= ',')\n",
    "    result_test_filename = \"result_file_test\" + str(j) +\".csv\"\n",
    "    test_result.to_csv(output_directory+result_test_filename , sep= ',')\n",
    "    ###train h를 file로\n",
    "    ###test h를 file로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
